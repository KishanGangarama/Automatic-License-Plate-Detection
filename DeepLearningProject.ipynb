{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0HzXxxS5l9Vj"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ['KAGGLE_USERNAME'] = 'kishangangarama'\n",
        "os.environ['KAGGLE_KEY'] = '9f07342104b36639a4ff81c22ded0a45'\n",
        "\n",
        "import kaggle\n",
        "kaggle.api.dataset_download_files('aslanahmedov/number-plate-detection', path='data', unzip=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import shutil\n",
        "import yaml\n",
        "from sklearn.model_selection import train_test_split\n",
        "from xml.etree import ElementTree as ET\n",
        "\n",
        "# Directory paths\n",
        "image_dir = '/content/data/images'\n",
        "annotation_dir = '/content/data/images'\n",
        "\n",
        "# Directories for the YOLO format dataset\n",
        "os.makedirs('/content/data/images/train', exist_ok=True)\n",
        "os.makedirs('/content/data/images/val', exist_ok=True)\n",
        "os.makedirs('/content/data/labels/train', exist_ok=True)\n",
        "os.makedirs('/content/data/labels/val', exist_ok=True)\n",
        "\n",
        "# Converting XML annotations to YOLO format\n",
        "def convert_annotation(image_id, list_with_all_boxes, save_dir, image_size):\n",
        "    out_file = open(f'{save_dir}/{image_id}.txt', 'w')\n",
        "    for box in list_with_all_boxes:\n",
        "        xmin, ymin, xmax, ymax = box\n",
        "        x_center = (xmin + xmax) / 2.0 / image_size[1]  # Normalize by width\n",
        "        y_center = (ymin + ymax) / 2.0 / image_size[0]  # Normalize by height\n",
        "        width = (xmax - xmin) / image_size[1]  # Normalize by width\n",
        "        height = (ymax - ymin) / image_size[0]  # Normalize by height\n",
        "        out_file.write(f'0 {x_center} {y_center} {width} {height}\\n')\n",
        "    out_file.close()\n",
        "\n",
        "# Get all original image ids and split data\n",
        "image_files = [os.path.splitext(f)[0] for f in os.listdir(image_dir) if f.endswith('.jpeg') and not f.endswith('_resized.jpeg')]\n",
        "train_ids, val_ids = train_test_split(image_files, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert annotations and split dataset\n",
        "for image_id in image_files:\n",
        "    image_path = f'{image_dir}/{image_id}.jpeg'\n",
        "    annotation_path = f'{annotation_dir}/{image_id}.xml'\n",
        "    image_size = cv2.imread(image_path).shape[:2]  # Get the size of the image (height, width)\n",
        "\n",
        "    # Check if the annotation file exists\n",
        "    if os.path.exists(annotation_path):\n",
        "        # Read the annotation file\n",
        "        tree = ET.parse(annotation_path)\n",
        "        root = tree.getroot()\n",
        "\n",
        "        list_with_all_boxes = []\n",
        "        for boxes in root.iter('object'):\n",
        "            ymin, xmin, ymax, xmax = None, None, None, None\n",
        "\n",
        "            ymin = int(boxes.find(\"bndbox/ymin\").text)\n",
        "            xmin = int(boxes.find(\"bndbox/xmin\").text)\n",
        "            ymax = int(boxes.find(\"bndbox/ymax\").text)\n",
        "            xmax = int(boxes.find(\"bndbox/xmax\").text)\n",
        "\n",
        "            list_with_single_boxes = [xmin, ymin, xmax, ymax]\n",
        "            list_with_all_boxes.append(list_with_single_boxes)\n",
        "\n",
        "        # Determine save directory (train or val)\n",
        "        save_dir = '/content/data/labels/train' if image_id in train_ids else '/content/data/labels/val'\n",
        "\n",
        "        # Convert and save annotations\n",
        "        convert_annotation(image_id, list_with_all_boxes, save_dir, image_size)\n",
        "\n",
        "        # Move images to respective train/val folders\n",
        "        new_image_path = f'/content/data/images/train/{image_id}.jpeg' if image_id in train_ids else f'/content/data/images/val/{image_id}.jpeg'\n",
        "        shutil.move(image_path, new_image_path)\n",
        "    else:\n",
        "        print(f\"Annotation file not found for {image_id}\")\n",
        "\n",
        "# Create the data.yaml file for training configuration\n",
        "data_yaml = {\n",
        "    'train': '/content/data/images/train',\n",
        "    'val': '/content/data/images/val',\n",
        "    'nc': 1,\n",
        "    'names': ['number_plate']  # Replace with your actual class name\n",
        "}\n",
        "\n",
        "with open('/content/data/data.yaml', 'w') as outfile:\n",
        "    yaml.dump(data_yaml, outfile, default_flow_style=False)\n",
        "\n",
        "print(\"Dataset preparation complete. Ready to train YOLOv5.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9evKvOMl-Nb",
        "outputId": "e436eb3c-83fe-44c5-c970-2570cd745332"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Annotation file not found for N180\n",
            "Annotation file not found for N249\n",
            "Annotation file not found for N182\n",
            "Dataset preparation complete. Ready to train YOLOv5.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ultralytics/yolov5.git\n",
        "%cd yolov5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORJ0ZdwsmP6j",
        "outputId": "b64a7aa5-160c-4372-d07b-640ac8735110"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 16098, done.\u001b[K\n",
            "remote: Counting objects: 100% (42/42), done.\u001b[K\n",
            "remote: Compressing objects: 100% (40/40), done.\u001b[K\n",
            "remote: Total 16098 (delta 15), reused 14 (delta 2), pack-reused 16056\u001b[K\n",
            "Receiving objects: 100% (16098/16098), 14.73 MiB | 6.51 MiB/s, done.\n",
            "Resolving deltas: 100% (11047/11047), done.\n",
            "/content/yolov5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "m204Rb4CmZoC",
        "outputId": "ddad3bb3-2da2-426b-e756-672f54fabcd4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gitpython>=3.1.30 (from -r requirements.txt (line 5))\n",
            "  Downloading GitPython-3.1.40-py3-none-any.whl (190 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/190.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m163.8/190.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=3.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.22.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (1.23.5)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (4.8.0.76)\n",
            "Collecting Pillow>=10.0.1 (from -r requirements.txt (line 9))\n",
            "  Downloading Pillow-10.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (3.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (5.9.5)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (1.11.4)\n",
            "Collecting thop>=0.1.1 (from -r requirements.txt (line 14))\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 15)) (2.1.0+cu118)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 16)) (0.16.0+cu118)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 17)) (4.66.1)\n",
            "Collecting ultralytics>=8.0.147 (from -r requirements.txt (line 18))\n",
            "  Downloading ultralytics-8.0.226-py3-none-any.whl (660 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m660.4/660.4 kB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 27)) (1.5.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 28)) (0.12.2)\n",
            "Requirement already satisfied: setuptools>=65.5.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 42)) (67.7.2)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython>=3.1.30->-r requirements.txt (line 5))\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (4.45.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (23.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (2.8.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (2023.11.17)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (2.1.0)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics>=8.0.147->-r requirements.txt (line 18)) (9.0.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2023.3.post1)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython>=3.1.30->-r requirements.txt (line 5))\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3->-r requirements.txt (line 6)) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->-r requirements.txt (line 15)) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->-r requirements.txt (line 15)) (1.3.0)\n",
            "Installing collected packages: smmap, Pillow, gitdb, thop, gitpython, ultralytics\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 9.4.0\n",
            "    Uninstalling Pillow-9.4.0:\n",
            "      Successfully uninstalled Pillow-9.4.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "imageio 2.31.6 requires pillow<10.1.0,>=8.3.2, but you have pillow 10.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Pillow-10.1.0 gitdb-4.0.11 gitpython-3.1.40 smmap-5.0.1 thop-0.1.1.post2209072238 ultralytics-8.0.226\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/ultralytics/yolov5/releases/download/v6.0/yolov5s.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mzvl3lktmeys",
        "outputId": "c053d7d8-27b1-44c4-8940-eccce8fd2e8e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-12-11 04:56:25--  https://github.com/ultralytics/yolov5/releases/download/v6.0/yolov5s.pt\n",
            "Resolving github.com (github.com)... 20.205.243.166\n",
            "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/264818686/eab38592-7168-4731-bdff-ad5ede2002be?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20231211%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20231211T045625Z&X-Amz-Expires=300&X-Amz-Signature=d51dcc57676337538169a59f949a2e283fafb53a2b19cf0bbe0f8ebeb0890365&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=264818686&response-content-disposition=attachment%3B%20filename%3Dyolov5s.pt&response-content-type=application%2Foctet-stream [following]\n",
            "--2023-12-11 04:56:25--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/264818686/eab38592-7168-4731-bdff-ad5ede2002be?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20231211%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20231211T045625Z&X-Amz-Expires=300&X-Amz-Signature=d51dcc57676337538169a59f949a2e283fafb53a2b19cf0bbe0f8ebeb0890365&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=264818686&response-content-disposition=attachment%3B%20filename%3Dyolov5s.pt&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14698491 (14M) [application/octet-stream]\n",
            "Saving to: ‘yolov5s.pt’\n",
            "\n",
            "yolov5s.pt          100%[===================>]  14.02M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2023-12-11 04:56:26 (130 MB/s) - ‘yolov5s.pt’ saved [14698491/14698491]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --img 640 --batch 16 --epochs 50 --data /content/data/data.yaml --weights yolov5s.pt --cache"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "plcvAcjVmlDN",
        "outputId": "29b14a84-5e0d-4f26-a627-4434c9143a56"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-12-11 04:56:39.346680: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-11 04:56:39.346761: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-11 04:56:39.346814: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=/content/data/data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=50, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n",
            "YOLOv5 🚀 v7.0-247-g3f02fde Python-3.10.12 torch-2.1.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n",
            "100% 755k/755k [00:00<00:00, 72.0MB/s]\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
            "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     16182  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "Model summary: 214 layers, 7022326 parameters, 7022326 gradients, 15.9 GFLOPs\n",
            "\n",
            "Transferred 343/349 items from yolov5s.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/data/labels/train... 179 images, 0 backgrounds, 0 corrupt: 100% 179/179 [00:00<00:00, 1651.18it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/data/labels/train.cache\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB ram): 100% 179/179 [00:01<00:00, 104.11it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/data/labels/val... 46 images, 0 backgrounds, 0 corrupt: 100% 46/46 [00:00<00:00, 610.39it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/data/labels/val.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.0GB ram): 100% 46/46 [00:00<00:00, 60.08it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m3.49 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
            "Plotting labels to runs/train/exp/labels.jpg... \n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/exp\u001b[0m\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       0/49      3.46G     0.1154    0.02762          0          6        640: 100% 12/12 [00:08<00:00,  1.46it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:02<00:00,  1.17s/it]\n",
            "                   all         46         46     0.0214     0.0217     0.0303    0.00343\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       1/49       3.9G    0.09154    0.02599          0          6        640: 100% 12/12 [00:03<00:00,  3.93it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:01<00:00,  1.66it/s]\n",
            "                   all         46         46    0.00196      0.587    0.00554     0.0011\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       2/49       3.9G    0.07991    0.02348          0          3        640: 100% 12/12 [00:03<00:00,  3.30it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:00<00:00,  3.16it/s]\n",
            "                   all         46         46    0.00955      0.696     0.0497     0.0152\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       3/49       3.9G    0.07468    0.02135          0          6        640: 100% 12/12 [00:02<00:00,  4.11it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:00<00:00,  3.22it/s]\n",
            "                   all         46         46     0.0029       0.87     0.0806     0.0202\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       4/49       3.9G    0.07119    0.02029          0          4        640: 100% 12/12 [00:02<00:00,  4.56it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:00<00:00,  3.29it/s]\n",
            "                   all         46         46     0.0261       0.87       0.29     0.0765\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       5/49       3.9G    0.06499    0.01993          0          4        640: 100% 12/12 [00:03<00:00,  3.17it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:01<00:00,  1.76it/s]\n",
            "                   all         46         46      0.147      0.717      0.293        0.1\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       6/49       3.9G    0.05941     0.0192          0          2        640: 100% 12/12 [00:02<00:00,  4.56it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:00<00:00,  3.79it/s]\n",
            "                   all         46         46        0.3      0.435      0.309      0.103\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       7/49       3.9G    0.05925     0.0188          0          5        640: 100% 12/12 [00:03<00:00,  3.86it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:00<00:00,  3.39it/s]\n",
            "                   all         46         46       0.25      0.587      0.207     0.0726\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       8/49       3.9G    0.05857    0.01896          0          7        640: 100% 12/12 [00:03<00:00,  3.85it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:00<00:00,  2.20it/s]\n",
            "                   all         46         46       0.39      0.457      0.423      0.115\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       9/49       3.9G    0.05494    0.01701          0          5        640: 100% 12/12 [00:03<00:00,  3.19it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:00<00:00,  3.44it/s]\n",
            "                   all         46         46      0.504       0.63       0.61      0.243\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      10/49       3.9G    0.05035    0.01789          0          8        640: 100% 12/12 [00:02<00:00,  4.58it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:00<00:00,  3.97it/s]\n",
            "                   all         46         46      0.657      0.587      0.673      0.176\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      11/49       3.9G    0.05151    0.01596          0          5        640: 100% 12/12 [00:02<00:00,  4.35it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:00<00:00,  4.13it/s]\n",
            "                   all         46         46      0.647      0.696      0.749      0.353\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      12/49       3.9G    0.04555    0.01591          0          5        640: 100% 12/12 [00:03<00:00,  3.77it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:01<00:00,  1.85it/s]\n",
            "                   all         46         46      0.868      0.783      0.886      0.478\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      13/49       3.9G    0.04365    0.01593          0          3        640: 100% 12/12 [00:03<00:00,  3.79it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:00<00:00,  3.99it/s]\n",
            "                   all         46         46      0.789      0.783      0.843      0.334\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      14/49       3.9G    0.04329    0.01478          0          4        640: 100% 12/12 [00:02<00:00,  4.49it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:00<00:00,  4.26it/s]\n",
            "                   all         46         46      0.838      0.787      0.891      0.435\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      15/49       3.9G    0.04049    0.01366          0          4        640: 100% 12/12 [00:02<00:00,  4.56it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:00<00:00,  4.06it/s]\n",
            "                   all         46         46      0.868      0.804      0.928      0.428\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      16/49       3.9G    0.03934    0.01296          0          5        640: 100% 12/12 [00:05<00:00,  2.16it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:01<00:00,  1.69it/s]\n",
            "                   all         46         46      0.799      0.866      0.916      0.465\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      17/49       3.9G     0.0404    0.01297          0          2        640: 100% 12/12 [00:03<00:00,  3.44it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:00<00:00,  3.75it/s]\n",
            "                   all         46         46       0.93      0.868      0.959      0.546\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      18/49       3.9G    0.03727    0.01224          0          7        640: 100% 12/12 [00:02<00:00,  4.16it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:00<00:00,  2.47it/s]\n",
            "                   all         46         46      0.931      0.878      0.954       0.52\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      19/49       3.9G    0.03581    0.01141          0          3        640: 100% 12/12 [00:04<00:00,  2.58it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:00<00:00,  2.02it/s]\n",
            "                   all         46         46      0.976      0.892      0.969      0.495\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      20/49       3.9G    0.03631    0.01116          0          9        640: 100% 12/12 [00:03<00:00,  3.56it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:00<00:00,  2.29it/s]\n",
            "                   all         46         46      0.976      0.894      0.965      0.477\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      21/49       3.9G    0.03496    0.01016          0          5        640: 100% 12/12 [00:02<00:00,  4.33it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:00<00:00,  4.12it/s]\n",
            "                   all         46         46       0.93      0.873      0.966      0.458\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      22/49       3.9G    0.03406    0.01008          0          7        640: 100% 12/12 [00:03<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:01<00:00,  1.48it/s]\n",
            "                   all         46         46       0.97      0.848      0.962      0.558\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      23/49       3.9G    0.03393    0.01086          0         10        640: 100% 12/12 [00:03<00:00,  3.11it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:00<00:00,  2.05it/s]\n",
            "                   all         46         46      0.915      0.935      0.966      0.538\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      24/49       3.9G    0.03337    0.01071          0          8        640: 100% 12/12 [00:02<00:00,  4.42it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:00<00:00,  4.15it/s]\n",
            "                   all         46         46      0.975      0.935      0.978      0.623\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      25/49       3.9G    0.03263   0.008816          0          4        640: 100% 12/12 [00:02<00:00,  4.19it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:00<00:00,  2.98it/s]\n",
            "                   all         46         46      0.977      0.934      0.981      0.574\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      26/49       3.9G    0.02965   0.009027          0          4        640: 100% 12/12 [00:03<00:00,  3.19it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:00<00:00,  2.83it/s]\n",
            "                   all         46         46      0.977      0.932      0.984      0.587\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      27/49       3.9G     0.0295   0.008411          0          4        640: 100% 12/12 [00:02<00:00,  4.75it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:00<00:00,  3.34it/s]\n",
            "                   all         46         46      0.977      0.932      0.987      0.608\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      28/49       3.9G    0.02962   0.007826          0          4        640: 100% 12/12 [00:02<00:00,  4.50it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:00<00:00,  4.35it/s]\n",
            "                   all         46         46      0.977      0.943       0.99      0.633\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      29/49       3.9G    0.02874   0.008223          0          4        640: 100% 12/12 [00:02<00:00,  4.20it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:00<00:00,  2.26it/s]\n",
            "                   all         46         46      0.977      0.944      0.988      0.632\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      30/49       3.9G    0.02791   0.008146          0          4        640: 100% 12/12 [00:03<00:00,  3.22it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:00<00:00,  3.29it/s]\n",
            "                   all         46         46      0.991      0.913      0.981      0.631\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      31/49       3.9G    0.02857   0.007842          0          6        640: 100% 12/12 [00:02<00:00,  4.53it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:00<00:00,  4.08it/s]\n",
            "                   all         46         46      0.957      0.965      0.987      0.586\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      32/49       3.9G    0.02689   0.008165          0          5        640: 100% 12/12 [00:02<00:00,  4.48it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:00<00:00,  3.85it/s]\n",
            "                   all         46         46      0.988      0.935      0.986      0.635\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      33/49       3.9G    0.02608   0.007909          0          5        640: 100% 12/12 [00:03<00:00,  3.82it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:01<00:00,  1.80it/s]\n",
            "                   all         46         46      0.992      0.935      0.989      0.686\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      34/49       3.9G    0.02566   0.007907          0          3        640: 100% 12/12 [00:03<00:00,  3.89it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:00<00:00,  3.60it/s]\n",
            "                   all         46         46      0.953      0.978      0.991      0.673\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      35/49       3.9G    0.02543   0.007371          0          4        640: 100% 12/12 [00:02<00:00,  4.44it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:00<00:00,  4.07it/s]\n",
            "                   all         46         46      0.939      0.996      0.991      0.685\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      36/49       3.9G    0.02648   0.007554          0          6        640: 100% 12/12 [00:02<00:00,  4.46it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:00<00:00,  4.34it/s]\n",
            "                   all         46         46      0.952      0.957       0.99      0.664\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      37/49       3.9G     0.0246   0.007503          0          6        640: 100% 12/12 [00:03<00:00,  3.66it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:01<00:00,  1.73it/s]\n",
            "                   all         46         46      0.938      0.995      0.991      0.677\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      38/49       3.9G      0.024   0.007428          0          5        640: 100% 12/12 [00:03<00:00,  3.84it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:00<00:00,  3.97it/s]\n",
            "                   all         46         46      0.957      0.973      0.991      0.674\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      39/49       3.9G    0.02425   0.007088          0          3        640: 100% 12/12 [00:02<00:00,  4.49it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:00<00:00,  4.19it/s]\n",
            "                   all         46         46      0.958      0.957      0.991      0.685\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      40/49       3.9G    0.02242   0.007122          0          6        640: 100% 12/12 [00:02<00:00,  4.40it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:00<00:00,  4.07it/s]\n",
            "                   all         46         46      0.978      0.974      0.992      0.672\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      41/49       3.9G    0.02244   0.006375          0          6        640: 100% 12/12 [00:03<00:00,  3.16it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:00<00:00,  2.04it/s]\n",
            "                   all         46         46      0.995      0.978      0.993      0.681\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      42/49       3.9G    0.02301    0.00711          0          6        640: 100% 12/12 [00:02<00:00,  4.14it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:00<00:00,  3.71it/s]\n",
            "                   all         46         46      0.974      0.978      0.993      0.681\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      43/49       3.9G    0.02215   0.006643          0          8        640: 100% 12/12 [00:02<00:00,  4.38it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:00<00:00,  4.25it/s]\n",
            "                   all         46         46      0.977      0.978      0.992      0.638\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      44/49       3.9G     0.0213   0.006993          0          4        640: 100% 12/12 [00:02<00:00,  4.58it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:00<00:00,  3.85it/s]\n",
            "                   all         46         46      0.978      0.978      0.991      0.675\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      45/49       3.9G    0.01988   0.006432          0          4        640: 100% 12/12 [00:03<00:00,  3.22it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:01<00:00,  1.84it/s]\n",
            "                   all         46         46      0.978      0.978      0.991      0.676\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      46/49       3.9G    0.02122    0.00666          0          4        640: 100% 12/12 [00:02<00:00,  4.47it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:00<00:00,  3.48it/s]\n",
            "                   all         46         46      0.978      0.976      0.991       0.68\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      47/49       3.9G    0.02085   0.006577          0          7        640: 100% 12/12 [00:02<00:00,  4.65it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:00<00:00,  3.10it/s]\n",
            "                   all         46         46      0.978      0.977       0.99      0.682\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      48/49       3.9G    0.01964    0.00691          0          6        640: 100% 12/12 [00:02<00:00,  4.54it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:00<00:00,  3.33it/s]\n",
            "                   all         46         46      0.978      0.975       0.99      0.679\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      49/49       3.9G    0.01959   0.007156          0          7        640: 100% 12/12 [00:04<00:00,  2.82it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:01<00:00,  1.92it/s]\n",
            "                   all         46         46      0.978      0.972       0.99      0.682\n",
            "\n",
            "50 epochs completed in 0.063 hours.\n",
            "Optimizer stripped from runs/train/exp/weights/last.pt, 14.4MB\n",
            "Optimizer stripped from runs/train/exp/weights/best.pt, 14.4MB\n",
            "\n",
            "Validating runs/train/exp/weights/best.pt...\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:00<00:00,  2.47it/s]\n",
            "                   all         46         46      0.992      0.935      0.989      0.676\n",
            "Results saved to \u001b[1mruns/train/exp\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python detect.py --weights /content/yolov5/runs/train/exp/weights/best.pt --img 640 --conf 0.25 --source /content/data/TEST/TEST.jpeg --save-txt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdjFIiNg0mnk",
        "outputId": "23552d5b-9b19-4c67-90f4-d342a17b9f05"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/yolov5/runs/train/exp/weights/best.pt'], source=/content/data/TEST/TEST.jpeg, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=True, save_csv=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLOv5 🚀 v7.0-247-g3f02fde Python-3.10.12 torch-2.1.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
            "image 1/1 /content/data/TEST/TEST.jpeg: 544x640 1 number_plate, 42.7ms\n",
            "Speed: 0.5ms pre-process, 42.7ms inference, 1.5ms NMS per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/exp\u001b[0m\n",
            "1 labels saved to runs/detect/exp/labels\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "detection_folder = '/content/yolov5/runs/detect/exp/labels'\n",
        "image_name = 'TEST.jpeg'  # your test image name\n",
        "txt_filename = os.path.splitext(image_name)[0] + '.txt'\n",
        "\n",
        "# Path to the .txt file with detections for the image\n",
        "detection_path = os.path.join(detection_folder, txt_filename)\n",
        "\n",
        "# Read the detection file\n",
        "if os.path.exists(detection_path):\n",
        "    with open(detection_path, 'r') as file:\n",
        "        for line in file.readlines():\n",
        "            # Each line corresponds to one detected object\n",
        "            class_id, x_center, y_center, width, height = [float(x) for x in line.split()]\n",
        "            # You may need to scale these coordinates if they're normalized\n",
        "            print(f'Detection: Class ID: {class_id}, Bounding Box: {x_center}, {y_center}, {width}, {height}')\n",
        "else:\n",
        "    print(f'No detection file found for {image_name}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "n5G00v0MyCj_",
        "outputId": "6a448445-ecd3-4efe-8eda-8e24d0cf241a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detection: Class ID: 0.0, Bounding Box: 0.506104, 0.705075, 0.279689, 0.0740741\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytesseract"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "9u6wczngwGbv",
        "outputId": "b582ae63-95c5-42b9-94d4-0d09b05178f3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.10-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (23.2)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (10.1.0)\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.3.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install tesseract-ocr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "VGxkm492wIG0",
        "outputId": "a2c582ca-15f7-41a1-df11-c33637430e17"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  tesseract-ocr-eng tesseract-ocr-osd\n",
            "The following NEW packages will be installed:\n",
            "  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n",
            "0 upgraded, 3 newly installed, 0 to remove and 15 not upgraded.\n",
            "Need to get 4,816 kB of archives.\n",
            "After this operation, 15.6 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-eng all 1:4.00~git30-7274cfa-1.1 [1,591 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-osd all 1:4.00~git30-7274cfa-1.1 [2,990 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr amd64 4.1.1-2.1build1 [236 kB]\n",
            "Fetched 4,816 kB in 1s (4,919 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package tesseract-ocr-eng.\n",
            "(Reading database ... 120899 files and directories currently installed.)\n",
            "Preparing to unpack .../tesseract-ocr-eng_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr-osd.\n",
            "Preparing to unpack .../tesseract-ocr-osd_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr.\n",
            "Preparing to unpack .../tesseract-ocr_4.1.1-2.1build1_amd64.deb ...\n",
            "Unpacking tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Setting up tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "import pytesseract\n",
        "from pytesseract import Output\n",
        "\n",
        "# Load the image where detection was performed\n",
        "image_path = '/content/data/TEST/TEST.jpeg'\n",
        "image = cv2.imread(image_path)\n",
        "\n",
        "# Check if the image was loaded correctly\n",
        "if image is None:\n",
        "    raise ValueError(f\"Image not found at the path: {image_path}\")\n",
        "\n",
        "\n",
        "x_center, y_center, bbox_width, bbox_height =  0.506104, 0.705075, 0.279689, 0.0740741\n",
        "\n",
        "# Calculate the actual pixel coordinates\n",
        "img_height, img_width, _ = image.shape\n",
        "x1 = int((x_center - bbox_width / 2) * img_width)\n",
        "y1 = int((y_center - bbox_height / 2) * img_height)\n",
        "x2 = int((x_center + bbox_width / 2) * img_width)\n",
        "y2 = int((y_center + bbox_height / 2) * img_height)\n",
        "\n",
        "# Crop the license plate region\n",
        "license_plate = image[y1:y2, x1:x2]\n",
        "\n",
        "# Preprocess the license plate image\n",
        "gray = cv2.cvtColor(license_plate, cv2.COLOR_BGR2GRAY)\n",
        "blur = cv2.GaussianBlur(gray, (3, 3), 0)\n",
        "thresh = cv2.adaptiveThreshold(blur, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
        "\n",
        "# Use Tesseract to do OCR on the processed image\n",
        "custom_config = r'--oem 3 --psm 8 -c tessedit_char_whitelist=0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
        "license_plate_number = pytesseract.image_to_string(thresh, config=custom_config)\n",
        "\n",
        "# Draw rectangles around detected characters (for visualization)\n",
        "d = pytesseract.image_to_data(thresh, output_type=Output.DICT, config=custom_config)\n",
        "n_boxes = len(d['level'])\n",
        "for i in range(n_boxes):\n",
        "    if int(d['conf'][i]) > 0:  # Confidence > 0 means Tesseract has recognized a character\n",
        "        (x, y, w, h) = (d['left'][i], d['top'][i], d['width'][i], d['height'][i])\n",
        "        cv2.rectangle(license_plate, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "\n",
        "# Display the OCR-processed image\n",
        "cv2_imshow(license_plate)\n",
        "\n",
        "print(\"Detected License Plate Number:\", license_plate_number.strip())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "Vd278UAzusqA",
        "outputId": "68fe9a5d-5029-4cf2-a835-773a0ea4bdc1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=252x54>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected License Plate Number: IKL51K4999\n"
          ]
        }
      ]
    }
  ]
}